{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78367408-486e-4769-9c4f-16868fae4aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.dsl import component, pipeline\n",
    "from kfp.v2.dsl import Dataset, Output, Input, Metrics, Markdown, Artifact\n",
    "from kfp.v2 import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630e9c82-b678-4991-921f-5331d6994ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177c18ca-9f59-4686-8ba0-8c077b164f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"gcr.io/ml-ops-segment-anything/sam:latest\"\n",
    ")\n",
    "def batch_prediction(\n",
    "    image_dir: str,\n",
    "    prompt_json_file: str,\n",
    "    visualization: Output[Markdown],\n",
    "    \n",
    "):\n",
    "    import torch\n",
    "    from typing import Dict, List\n",
    "    from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator\n",
    "    import base64\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import logging\n",
    "    from google.cloud import storage\n",
    "    import base64\n",
    "    import json\n",
    "    import time\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket('sam-pipeline-test')\n",
    "    # Get Model artifact from cloud storage\n",
    "    blob = bucket.blob('model_artifacts/sam_vit_b_01ec64.pth')\n",
    "    blob.download_to_filename('sam_vit_b_01ec64.pth')\n",
    "    \n",
    "    #Load the model\n",
    "    sam = sam_model_registry[\"vit_b\"](checkpoint=\"sam_vit_b_01ec64.pth\")\n",
    "    print(torch.cuda.is_available())\n",
    "    sam.to(\"cuda\")\n",
    "    # Automatic mask generation\n",
    "    mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "    # SAM Masking with prompts\n",
    "    sam_predictor = SamPredictor(sam)\n",
    "    \n",
    "    # Initialize Images\n",
    "    blobs = bucket.list_blobs(prefix=image_dir)\n",
    "    image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    image_blobs = [blob for blob in blobs if blob.name.lower().endswith(image_extensions)]\n",
    "    \n",
    "    #Prompt Json\n",
    "    blob = bucket.blob(f'{image_dir}/{prompt_json_file}')\n",
    "    prompt_json = json.loads(blob.download_as_text()) #returns prompts dictionary\n",
    "    \n",
    "    #Reshaping the image\n",
    "    def reshape_image(image, size=256):\n",
    "        # Ratio for showing up in Markdown\n",
    "        if image.shape[0] < size and image.shape[1] < size: \n",
    "            ratio = 1\n",
    "        else: \n",
    "            ratio = size / max(image.shape[0], image.shape[1])\n",
    "        width = int(image.shape[1] * ratio)\n",
    "        height = int(image.shape[0] * ratio)\n",
    "        image = cv2.resize(image, (width, height))\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    # Predict all images\n",
    "    results = []\n",
    "    for image_blob in image_blobs:\n",
    "        image_bytes = image_blob.download_as_bytes()\n",
    "        image_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
    "        print(image_blob.name)\n",
    "        jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "        image = cv2.cvtColor(cv2.imdecode(jpg_as_np, flags=1), cv2.COLOR_BGR2RGB)\n",
    "        # Image resizing\n",
    "        image = reshape_image(image)\n",
    "        # Encoding it to base64 string\n",
    "        image_base64 = base64.b64encode(cv2.imencode('.png', image)[1]).decode()\n",
    "        \n",
    "        # Predictions\n",
    "        prediction = {}\n",
    "        prediction[\"file_path\"] = image_blob.name\n",
    "        prediction[\"base64\"] = image_base64\n",
    "        prediction[\"image\"] = image.tolist()\n",
    "        prediction[\"masks\"] = {}\n",
    "        \n",
    "        if image_blob.name in prompt_json: # Predicting with prompt inputs\n",
    "            \n",
    "            prompt_input = np.array(prompt_json[image_blob.name]).reshape(1,2)\n",
    "            input_label = np.array([1])\n",
    "            start = time.time()\n",
    "            masks, scores, logits = sam_predictor.predict(\n",
    "                                        point_coords=prompt_input,\n",
    "                                        point_labels=input_label,\n",
    "                                        multimask_output=False\n",
    "                                        )\n",
    "            print(\"Prediction time taken(with prompts): \", time.time() - start)\n",
    "            h, w = masks.shape[-2:]\n",
    "            masks = masks.reshape(h, w)\n",
    "            prediction[\"masks\"]['mask_1'] = masks\n",
    "            prediction[\"prediction_type\"] = \"Predicting with Prompts\"\n",
    "            \n",
    "        else: # Predicting without prompt inputs\n",
    "            start = time.time()\n",
    "            masks = mask_generator.generate(image)\n",
    "            print(\"Prediction time taken(without prompts): \", time.time() - start)\n",
    "            sorted_masks = sorted(masks, key=(lambda x: x['area']), reverse=True)\n",
    "            for idx, mask in enumerate(sorted_masks):\n",
    "            # TODO: Rewrite the result format, add more related scores and save it into a single json, with mask index\n",
    "                prediction[\"masks\"][f'mask_{idx}'] = mask['segmentation'].tolist()\n",
    "            \n",
    "            prediction[\"prediction_type\"] = \"Predicting without Prompts\"\n",
    "        \n",
    "            \n",
    "        results.append(prediction)\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # TODO: Use Kubeflow Output to save json\n",
    "\n",
    "    # TODO: Optimize the visualization\n",
    "    with open(visualization.path, 'w') as f:\n",
    "        alpha = 0.5\n",
    "        for result in results:\n",
    "            image = np.array(result[\"image\"])\n",
    "            f.write(f\"## All Masks \\n\\n\")\n",
    "            f.write(f\"# {result['file_path']} \\n\\n\")\n",
    "            f.write(f\"# {result['prediction_type']} \\n\\n\")\n",
    "            f.write(\"<table><tr>\")\n",
    "            f.write(f'<td><img src=\"data:image/*;base64,{result[\"base64\"]}\" width=100% align=\"left\"></td></tr>')\n",
    "            for mask_name, mask in result[\"masks\"].items():\n",
    "                f.write(f\"## {mask_name} \\n\\n\")\n",
    "                mask = np.array(mask)\n",
    "                mask_color = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "                mask_color[mask == 0] = [0, 0, 0]\n",
    "                mask_color[mask == 1] = [150, 0, 0]\n",
    "                mask = np.array(mask)\n",
    "                image[mask==1, :] = (1-alpha) * image[mask==1, :] + alpha * mask_color[mask==1, :3]\n",
    "                image_base64 = base64.b64encode(cv2.imencode('.png', image)[1]).decode()\n",
    "                f.write(\"<tr>\")\n",
    "                f.write(f'<td><img src=\"data:image/*;base64,{image_base64}\" width=100% align=\"left\"></td>')\n",
    "                f.write(\"</tr>\")\n",
    "            f.write(\"</table>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fcf66db-b3af-4d01-a375-5468469446da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Initialization\n",
    "@pipeline(\n",
    "    pipeline_root=\"gs://sam-pipeline-test\",\n",
    "    name=\"sam-pipeline-test\",\n",
    ")\n",
    "def sam_pipeline(\n",
    "    image_dir: str = \"batch_5\"\n",
    "):\n",
    "    get_batch_prediction_op = (batch_prediction(image_dir=image_dir, prompt_json_file = \"prompts_json_5.jsonl\")\n",
    "        .set_cpu_limit(\"8\")\n",
    "        .set_memory_limit(\"64G\")\n",
    "        .add_node_selector_constraint(\"cloud.google.com/gke-accelerator\", \"NVIDIA_TESLA_T4\")\n",
    "        .set_gpu_limit(1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "536847ff-ed5f-4bea-bfbb-943646b110dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=sam_pipeline,\n",
    "    package_path='sam_pipe_test.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb080531-87e7-4509-900c-ff221113dc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://sam_pipe_test.json [Content-Type=application/json]...\n",
      "/ [1 files][  6.1 KiB/  6.1 KiB]                                                \n",
      "Operation completed over 1 objects/6.1 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp sam_pipe_test.json gs://sam-pipeline-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f063d069-2ff6-4463-83fc-65316b00fd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/633534855904/locations/us-west1/pipelineJobs/sam-pipeline-test-20230726161253\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/633534855904/locations/us-west1/pipelineJobs/sam-pipeline-test-20230726161253')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-west1/pipelines/runs/sam-pipeline-test-20230726161253?project=633534855904\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "job = aiplatform.PipelineJob(display_name = 'sam_test-1',\n",
    "                             template_path = 'sam_pipe_test.json',\n",
    "                             enable_caching = False,\n",
    "                             # failure_policy = \"slow\",\n",
    "                             project=\"ml-ops-segment-anything\",\n",
    "                             location=\"us-west1\",\n",
    "                            )\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deca89f5-960c-4571-ab98-5c5d0b2ce8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfp                                    1.8.22\n",
      "kfp-pipeline-spec                      0.1.16\n",
      "kfp-server-api                         1.8.5\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep \"kfp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d422cdd-3047-4d33-9f7e-ac96a8db0390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kfp==1.8.22\n",
      "  Downloading kfp-1.8.22.tar.gz (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.9/304.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py<2,>=0.9 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.4.0)\n",
      "Requirement already satisfied: PyYAML<7,>=5.3 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (5.4.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-storage<3,>=1.20.0 in ./.local/lib/python3.10/site-packages (from kfp==1.8.22) (1.44.0)\n",
      "Requirement already satisfied: kubernetes<26,>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (25.3.0)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.8.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.1 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (2.17.3)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.10.1)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (2.2.1)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.8.5)\n",
      "Requirement already satisfied: jsonschema<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (4.17.3)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.9.0)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (8.1.3)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.2.13)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.1.10)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.15)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.16 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.1.16)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.5.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (3.20.3)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (3.0.1)\n",
      "Requirement already satisfied: urllib3<2 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.26.15)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.10.7)\n",
      "Requirement already satisfied: typer<1.0,>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.7.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from Deprecated<2,>=1.2.7->kfp==1.8.22) (1.15.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire<1,>=0.3.1->kfp==1.8.22) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire<1,>=0.3.1->kfp==1.8.22) (2.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.22) (1.59.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.22) (2.28.2)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.22) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.22) (0.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.1->kfp==1.8.22) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.1->kfp==1.8.22) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.1->kfp==1.8.22) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3,>=1.20.0->kfp==1.8.22) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3,>=1.20.0->kfp==1.8.22) (2.5.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5,>=3.0.1->kfp==1.8.22) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5,>=3.0.1->kfp==1.8.22) (0.19.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.22) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.22) (2.8.2)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes<26,>=8.0.0->kfp==1.8.22) (67.7.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes<26,>=8.0.0->kfp==1.8.22) (1.5.1)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes<26,>=8.0.0->kfp==1.8.22) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<2,>=1.8.2->kfp==1.8.22) (4.5.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from strip-hints<1,>=0.1.8->kfp==1.8.22) (0.40.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<3,>=1.20.0->kfp==1.8.22) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client<2,>=1.7.8->kfp==1.8.22) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.1->kfp==1.8.22) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.22) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.22) (3.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib->kubernetes<26,>=8.0.0->kfp==1.8.22) (3.2.2)\n",
      "Building wheels for collected packages: kfp\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.8.22-py3-none-any.whl size=426971 sha256=76abdae182cf74a0ba6b45e327f7bbd65044fa748967d5865e8d6bcf5aa660bb\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/74/c0/fc/bf0ab209fd6ae814d7efbc821076e948c3e4884f846583ab58\n",
      "Successfully built kfp\n",
      "Installing collected packages: kfp\n",
      "  Attempting uninstall: kfp\n",
      "    Found existing installation: kfp 1.8.20\n",
      "    Uninstalling kfp-1.8.20:\n",
      "      Successfully uninstalled kfp-1.8.20\n",
      "Successfully installed kfp-1.8.22\n"
     ]
    }
   ],
   "source": [
    "!pip install kfp==1.8.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dba581ee-65ae-4c74-a22f-7eaa10872363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfp                                    1.8.22\n",
      "kfp-pipeline-spec                      0.1.16\n",
      "kfp-server-api                         1.8.5\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep \"kfp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98acd698-cd1b-4e3e-be80-e6b5e5cb73e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0,  0],\n",
      "       [ 0, 99],\n",
      "       [99, 99],\n",
      "       [99,  0]])]\n",
      "[[0, 0, 0, 99, 99, 99, 99, 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imantics import Polygons, Mask\n",
    "\n",
    "# This can be any array\n",
    "array = np.ones((100, 100))\n",
    "\n",
    "polygons = Mask(array).polygons()\n",
    "\n",
    "print(polygons.points)\n",
    "print(polygons.segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7eb9b79-e981-4a2a-9178-c217f76f4ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imantics\n",
      "  Downloading imantics-0.1.12.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from imantics) (1.23.5)\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from imantics) (4.7.0.72)\n",
      "Collecting lxml (from imantics)\n",
      "  Downloading lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl (7.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting xmljson (from imantics)\n",
      "  Downloading xmljson-0.2.1-py2.py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: imantics\n",
      "  Building wheel for imantics (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imantics: filename=imantics-0.1.12-py3-none-any.whl size=16015 sha256=734ccba4b3e2b9e3eb7b38e3e69eb4b18a41c9444275553093d02b1a35c98b93\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/56/6a/be/4c60e88b14abec4e93234a1f7f91ce8abe1ae88a2b3eaad3ac\n",
      "Successfully built imantics\n",
      "Installing collected packages: xmljson, lxml, imantics\n",
      "Successfully installed imantics-0.1.12 lxml-4.9.3 xmljson-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install imantics"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
