{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78367408-486e-4769-9c4f-16868fae4aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.dsl import component, pipeline\n",
    "from kfp.v2.dsl import Dataset, Output, Input, Metrics, Markdown, Artifact\n",
    "from kfp.v2 import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af668e-98e8-4b63-b146-216eebf28852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "177c18ca-9f59-4686-8ba0-8c077b164f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"gcr.io/ml-ops-segment-anything/sam:latest\",\n",
    "    packages_to_install=[\n",
    "        'imantics',\n",
    "        'scipy',\n",
    "        'matplotlib'\n",
    "    ]\n",
    ")\n",
    "def batch_prediction(\n",
    "    bucket_name: str,\n",
    "    input_dir: str,\n",
    "    output_dir: str,\n",
    "    prompt_json_file: str,\n",
    "    max_mask: int,\n",
    "    visualization: Output[Markdown],\n",
    "):\n",
    "    import torch\n",
    "    from typing import Dict, List\n",
    "    from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator\n",
    "    import base64\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import logging\n",
    "    from google.cloud import storage\n",
    "    import base64\n",
    "    import json\n",
    "    import time\n",
    "    from imantics import Polygons, Mask\n",
    "    from scipy.ndimage import median_filter\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def show_points(coords, labels, ax, marker_size=375):\n",
    "        pos_points = coords[labels==1]\n",
    "        neg_points = coords[labels==0]\n",
    "        ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "        ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)  \n",
    "\n",
    "    def show_mask(mask, ax, random_color=False):\n",
    "        if random_color:\n",
    "            color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "        else:\n",
    "            color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "        h, w = mask.shape[-2:]\n",
    "        mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "        ax.imshow(mask_image)\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    # Get Model artifact from cloud storage\n",
    "    blob = bucket.blob('model_artifacts/sam_vit_b_01ec64.pth')\n",
    "    blob.download_to_filename('sam_vit_b_01ec64.pth')\n",
    "    \n",
    "    #Load the model\n",
    "    sam = sam_model_registry[\"vit_b\"](checkpoint=\"sam_vit_b_01ec64.pth\")\n",
    "    print(torch.cuda.is_available())\n",
    "    sam.to(\"cuda\")\n",
    "    # Automatic mask generation\n",
    "    mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "    # SAM Masking with prompts\n",
    "    predictor = SamPredictor(sam)\n",
    "    \n",
    "    # Initialize Images\n",
    "    blobs = bucket.list_blobs(prefix=f\"{input_dir}/\")\n",
    "    image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    image_blobs = [blob for blob in blobs if blob.name.lower().endswith(image_extensions)]\n",
    "    \n",
    "    # Prompt Json\n",
    "    blob = bucket.blob(f'{input_dir}/{prompt_json_file}')\n",
    "    if blob.exists():\n",
    "        prompt_json = json.loads(blob.download_as_text()) #returns prompts dictionary\n",
    "    else:\n",
    "        prompt_json = None\n",
    "    print(\"prompt_json\")\n",
    "    print(prompt_json)\n",
    "\n",
    "    # Reshaping the image\n",
    "    def reshape_image(image, size=512):\n",
    "        # Ratio for showing up in Markdown\n",
    "        if image.shape[0] < size and image.shape[1] < size: \n",
    "            ratio = 1\n",
    "        else: \n",
    "            ratio = size / max(image.shape[0], image.shape[1])\n",
    "        width = int(image.shape[1] * ratio)\n",
    "        height = int(image.shape[0] * ratio)\n",
    "        image = cv2.resize(image, (width, height))\n",
    "        return ratio, image\n",
    "\n",
    "    # Predict all images\n",
    "    start_time_pred = time.time()\n",
    "    filenames, results = [], []\n",
    "    for image_blob in image_blobs:\n",
    "        filename = image_blob.name.split('/')[-1]\n",
    "        filenames.append(filename)\n",
    "        start_time = time.time()\n",
    "        image_blob.download_to_filename(filename)\n",
    "        print(f\"Image Downloading: {time.time() - start_time}s\")\n",
    "        ratio, image = reshape_image(cv2.cvtColor(cv2.imread(filename), cv2.COLOR_BGR2RGB))\n",
    "        if prompt_json and filename in prompt_json: # Predicting with prompt inputs\n",
    "            prompt_info = prompt_json[image_blob.name.split('/')[-1]]\n",
    "            prompt_input, label_input = [], []\n",
    "            for label, points in prompt_info.items():\n",
    "                for point in points:\n",
    "                    point = [int(c * ratio) for c in point]\n",
    "                    prompt_input.append(point)\n",
    "                    label_input.append(int(label))\n",
    "            predictor.set_image(image)\n",
    "            start_time = time.time()\n",
    "            masks, scores, logits = predictor.predict(\n",
    "                                        point_coords=np.array(prompt_input),\n",
    "                                        point_labels=np.array(label_input),\n",
    "                                        multimask_output=False\n",
    "                                    )\n",
    "            print(f\"Prediction with Prompt: {time.time() - start_time}s\")\n",
    "            start_time = time.time()\n",
    "            result = {\n",
    "                \"filename\": filename,\n",
    "                \"image\": image,\n",
    "                \"prediction_type\" : \"Predicting with Prompts\",\n",
    "                \"prompt_input\": prompt_input,\n",
    "                \"label_input\": label_input,\n",
    "                \"ratio\": ratio\n",
    "            }\n",
    "            result[\"masks\"], result[\"polygon_vertices\"] = {}, {}\n",
    "            for idx, mask in enumerate(masks[:max_mask]):\n",
    "                median_filter_size = int(min(mask.shape)//20)\n",
    "                if median_filter_size % 2 == 0:\n",
    "                    median_filter_size += 1\n",
    "                mask = median_filter(mask, median_filter_size)\n",
    "                result[\"masks\"][f'mask_{idx}'] = mask\n",
    "                polygons = Mask(mask).polygons()\n",
    "                result[\"polygon_vertices\"][f'mask_{idx}'] = list(map(lambda x: x.tolist(), polygons.points))\n",
    "            print(f\"Postprocessing {time.time() - start_time}s\")\n",
    "        else: # Predicting without prompt inputs\n",
    "            start_time = time.time()\n",
    "            masks = mask_generator.generate(image)\n",
    "            print(f\"Prediction without Prompt: {time.time() - start_time}s\")\n",
    "            result = {\n",
    "                \"filename\": filename,\n",
    "                \"image\": image,\n",
    "                \"prediction_type\" : \"Predicting without Prompts\",\n",
    "                \"ratio\": ratio\n",
    "            }\n",
    "            sorted_masks = sorted(masks, key=(lambda x: x['area']), reverse=True)\n",
    "            result[\"masks\"], result[\"polygon_vertices\"] = {}, {}\n",
    "            start_time = time.time()\n",
    "            for idx, mask in enumerate(sorted(masks, key=(lambda x: x['area']), reverse=True)[:max_mask]):\n",
    "                mask = mask['segmentation']\n",
    "                median_filter_size = int(min(mask.shape)//20)\n",
    "                if median_filter_size % 2 == 0:\n",
    "                    median_filter_size += 1\n",
    "                mask = median_filter(mask, median_filter_size)\n",
    "                result[\"masks\"][f'mask_{idx}'] = mask\n",
    "                polygons = Mask(mask).polygons()\n",
    "                result[\"polygon_vertices\"][f'mask_{idx}'] = list(map(lambda x: x.tolist(), polygons.points))\n",
    "            print(f\"Postprocessing {time.time() - start_time}s\")\n",
    "        results.append(result)\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f\"Time Taken for predictions, including preprocessing and postprocessing: {time.time() - start_time_pred}s\")\n",
    "\n",
    "    # Export Images to Output DIR\n",
    "    start_time = time.time()\n",
    "    alpha = 0.5\n",
    "    for filename, result in zip(filenames, results):\n",
    "        original_image_blob = bucket.blob(f\"{output_dir}/{filename}/original.jpg\")\n",
    "        original_image_blob.upload_from_filename(filename)\n",
    "        for mask_name, mask in result[\"masks\"].items():\n",
    "            # mask_color = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "            # mask_color[mask == 0] = [0, 0, 0]\n",
    "            # mask_color[mask == 1] = [255, 0, 0]\n",
    "            # img_mask = result['image'].copy()\n",
    "            # img_mask[mask==1, :] = (1-alpha) * img_mask[mask==1, :] + alpha * mask_color[mask==1, :3]\n",
    "            # cv2.imwrite(f'{mask_name}.jpg', cv2.cvtColor(img_mask, cv2.COLOR_RGB2BGR))  \n",
    "            mask = np.array(mask)\n",
    "            plt.figure(figsize=(10,10))\n",
    "            plt.imshow(result['image'])\n",
    "            show_mask(mask, plt)\n",
    "            if \"prompt_input\" in result:\n",
    "                input_point = np.array(result['prompt_input'])\n",
    "                input_label = np.array(result['label_input'])\n",
    "                show_points(input_point, input_label, plt)\n",
    "            plt.axis('off')\n",
    "            plt.savefig(f\"{mask_name}.jpg\")\n",
    "            plt.close()\n",
    "            bucket.blob(f\"{output_dir}/{filename}/{mask_name}.jpg\").upload_from_filename(f\"{mask_name}.jpg\")\n",
    "    print(f\"Time Taken for image exportations: {time.time() - start_time}s\")\n",
    "    \n",
    "    # Export Results to Output DIR\n",
    "    start_time = time.time()\n",
    "    for result in results:\n",
    "        output_result = {}\n",
    "        output_result[\"filename\"] = result[\"filename\"]\n",
    "        output_result[\"prediction_type\"] = result[\"prediction_type\"]\n",
    "        output_result[\"polygon_vertices\"] = result[\"polygon_vertices\"]\n",
    "        output_result[\"ratio\"] = result[\"ratio\"]\n",
    "        json_object = json.dumps(output_result, indent=4)\n",
    "        with open(\"result.json\", \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "        bucket.blob(f\"{output_dir}/{result['filename']}/result.json\").upload_from_filename(\"result.json\")\n",
    "    print(f\"Time Taken for json exportations: {time.time() - start_time}s\")\n",
    "        \n",
    "    # Visualization\n",
    "    with open(visualization.path, 'w') as f:\n",
    "        for result in results:\n",
    "            image = result[\"image\"]\n",
    "            f.write(f\"# {result['filename']} \\n\")\n",
    "            f.write(f\"## Prediction Type: {result['prediction_type']} \\n\")\n",
    "            f.write(\"<table>\")\n",
    "            f.write(\"<tr><td>\")\n",
    "            f.write(f'<img src=\"https://storage.cloud.google.com/{bucket_name}/{output_dir}/{result[\"filename\"]}/original.jpg\">')\n",
    "            f.write(\"</td>\")\n",
    "            f.write(\"<td></td><td></td><td></td></tr>\")\n",
    "            for idx, mask_name in enumerate(list(result[\"masks\"].keys())):\n",
    "                if idx % 4 == 0:\n",
    "                    f.write(\"<tr>\")\n",
    "                f.write(f'<td><img src=\"https://storage.cloud.google.com/{bucket_name}/{output_dir}/{result[\"filename\"]}/{mask_name}.jpg\"></td>')\n",
    "                if idx % 4 == 3:\n",
    "                    f.write(\"</tr>\")\n",
    "            if idx % 4 != 3:\n",
    "                f.write(\"</tr>\")\n",
    "            f.write(\"</table>\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4fcf66db-b3af-4d01-a375-5468469446da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Initialization\n",
    "@pipeline(\n",
    "    pipeline_root=\"gs://sam-pipeline-test\",\n",
    "    name=\"sam-pipeline-test-batch-100\",\n",
    ")\n",
    "def sam_pipeline(\n",
    "    bucket_name: str = \"sam-pipeline-test\",\n",
    "    input_dir: str = \"batch_10\",\n",
    "    output_dir: str = \"batch_10_output\",\n",
    "    prompt_json_file: str = \"dummy\",\n",
    "    max_mask: int = 10\n",
    "):\n",
    "    get_batch_prediction_op = (batch_prediction(\n",
    "        bucket_name=bucket_name,\n",
    "        input_dir=input_dir, \n",
    "        output_dir=output_dir,\n",
    "        prompt_json_file=prompt_json_file,\n",
    "        max_mask=max_mask\n",
    "    )\n",
    "        .set_cpu_limit(\"8\")\n",
    "        .set_memory_limit(\"64G\")\n",
    "        .add_node_selector_constraint(\"cloud.google.com/gke-accelerator\", \"NVIDIA_TESLA_T4\")\n",
    "        .set_gpu_limit(1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "536847ff-ed5f-4bea-bfbb-943646b110dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=sam_pipeline,\n",
    "    package_path='sam_pipe_test.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb080531-87e7-4509-900c-ff221113dc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://sam_pipe_test.json [Content-Type=application/json]...\n",
      "/ [1 files][ 14.0 KiB/ 14.0 KiB]                                                \n",
      "Operation completed over 1 objects/14.0 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp sam_pipe_test.json gs://sam-pipeline-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f063d069-2ff6-4463-83fc-65316b00fd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/633534855904/locations/us-central1/pipelineJobs/sam-pipeline-test-batch-100-20230728052635\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/633534855904/locations/us-central1/pipelineJobs/sam-pipeline-test-batch-100-20230728052635')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/sam-pipeline-test-batch-100-20230728052635?project=633534855904\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "job = aiplatform.PipelineJob(display_name = 'wallace_test',\n",
    "                             template_path = 'sam_pipe_test.json',\n",
    "                             enable_caching = False,\n",
    "                             # failure_policy = \"slow\",\n",
    "                             project=\"ml-ops-segment-anything\",\n",
    "                             location=\"us-central1\",\n",
    "                            )\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deca89f5-960c-4571-ab98-5c5d0b2ce8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfp                                    1.8.22\n",
      "kfp-pipeline-spec                      0.1.16\n",
      "kfp-server-api                         1.8.5\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep \"kfp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d422cdd-3047-4d33-9f7e-ac96a8db0390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kfp==1.8.22\n",
      "  Downloading kfp-1.8.22.tar.gz (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.9/304.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py<2,>=0.9 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.4.0)\n",
      "Requirement already satisfied: PyYAML<7,>=5.3 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (5.4.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-storage<3,>=1.20.0 in ./.local/lib/python3.10/site-packages (from kfp==1.8.22) (1.44.0)\n",
      "Requirement already satisfied: kubernetes<26,>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (25.3.0)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.8.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.1 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (2.17.3)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.10.1)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (2.2.1)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.8.5)\n",
      "Requirement already satisfied: jsonschema<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (4.17.3)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.9.0)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (8.1.3)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.2.13)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.1.10)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.15)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.16 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.1.16)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.5.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (3.20.3)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (3.0.1)\n",
      "Requirement already satisfied: urllib3<2 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.26.15)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (1.10.7)\n",
      "Requirement already satisfied: typer<1.0,>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from kfp==1.8.22) (0.7.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from Deprecated<2,>=1.2.7->kfp==1.8.22) (1.15.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire<1,>=0.3.1->kfp==1.8.22) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire<1,>=0.3.1->kfp==1.8.22) (2.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.22) (1.59.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.22) (2.28.2)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.22) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.22) (0.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.1->kfp==1.8.22) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.1->kfp==1.8.22) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.1->kfp==1.8.22) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3,>=1.20.0->kfp==1.8.22) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3,>=1.20.0->kfp==1.8.22) (2.5.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5,>=3.0.1->kfp==1.8.22) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5,>=3.0.1->kfp==1.8.22) (0.19.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.22) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.22) (2.8.2)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes<26,>=8.0.0->kfp==1.8.22) (67.7.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes<26,>=8.0.0->kfp==1.8.22) (1.5.1)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes<26,>=8.0.0->kfp==1.8.22) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<2,>=1.8.2->kfp==1.8.22) (4.5.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from strip-hints<1,>=0.1.8->kfp==1.8.22) (0.40.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<3,>=1.20.0->kfp==1.8.22) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client<2,>=1.7.8->kfp==1.8.22) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.1->kfp==1.8.22) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.22) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.22) (3.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib->kubernetes<26,>=8.0.0->kfp==1.8.22) (3.2.2)\n",
      "Building wheels for collected packages: kfp\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.8.22-py3-none-any.whl size=426971 sha256=76abdae182cf74a0ba6b45e327f7bbd65044fa748967d5865e8d6bcf5aa660bb\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/74/c0/fc/bf0ab209fd6ae814d7efbc821076e948c3e4884f846583ab58\n",
      "Successfully built kfp\n",
      "Installing collected packages: kfp\n",
      "  Attempting uninstall: kfp\n",
      "    Found existing installation: kfp 1.8.20\n",
      "    Uninstalling kfp-1.8.20:\n",
      "      Successfully uninstalled kfp-1.8.20\n",
      "Successfully installed kfp-1.8.22\n"
     ]
    }
   ],
   "source": [
    "!pip install kfp==1.8.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dba581ee-65ae-4c74-a22f-7eaa10872363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfp                                    1.8.22\n",
      "kfp-pipeline-spec                      0.1.16\n",
      "kfp-server-api                         1.8.5\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep \"kfp\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
