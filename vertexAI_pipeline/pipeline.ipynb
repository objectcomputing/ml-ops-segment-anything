{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4002c91d-2b1c-442b-8743-b8381ee29bf3",
   "metadata": {},
   "source": [
    "## **Setting up Pipeline Job using Kubeflow SDK in Component Based Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78367408-486e-4769-9c4f-16868fae4aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.dsl import component, pipeline\n",
    "from kfp.v2.dsl import Dataset, Output, Input, Metrics, Markdown, Artifact\n",
    "from kfp.v2 import compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b691e-fbd9-4ffc-abb6-2e03a460c07a",
   "metadata": {},
   "source": [
    "### Batch Prediction Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "177c18ca-9f59-4686-8ba0-8c077b164f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"gcr.io/ml-ops-segment-anything/sam:latest\",\n",
    "    packages_to_install=[\n",
    "        'imantics',\n",
    "        'scipy',\n",
    "        'matplotlib'\n",
    "    ]\n",
    ")\n",
    "def batch_prediction(\n",
    "    bucket_name: str,\n",
    "    input_dir: str,\n",
    "    output_dir: str,\n",
    "    prompt_json_file: str,\n",
    "    max_mask: int,\n",
    "    visualization: Output[Markdown],\n",
    "):\n",
    "    \"\"\" The following imports are specific to t\"\"\"\n",
    "    import torch\n",
    "    from typing import Dict, List\n",
    "    from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator\n",
    "    import base64\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import logging\n",
    "    from google.cloud import storage\n",
    "    import base64\n",
    "    import json\n",
    "    import time\n",
    "    from imantics import Polygons, Mask\n",
    "    from scipy.ndimage import median_filter\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def show_points(coords, labels, ax, marker_size=375):\n",
    "        \"\"\"\n",
    "            Show marker points on the image for the co-ordinates.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            coords : np.ndarray\n",
    "                prompt co-ordinates\n",
    "            labels : int\n",
    "                object label\n",
    "            ax : subplot\n",
    "                current axes\n",
    "            marker_size: int\n",
    "                Optional\n",
    "            Returns\n",
    "            -------\n",
    "            None\n",
    "        \"\"\"\n",
    "        pos_points = coords[labels==1]\n",
    "        neg_points = coords[labels==0]\n",
    "        ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "        ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)  \n",
    "\n",
    "    def show_mask(mask, ax, random_color=False):\n",
    "        \"\"\"\n",
    "            Applies mask for an object in the image.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            mask : np.ndarray\n",
    "                object mask\n",
    "            ax : subplot\n",
    "                current axes\n",
    "            random_color: Boolean\n",
    "                Optional\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            None\n",
    "        \"\"\"\n",
    "        if random_color:\n",
    "            color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "        else:\n",
    "            color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "        h, w = mask.shape[-2:]\n",
    "        mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "        ax.imshow(mask_image)\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    \"\"\" Get Model artifact from cloud storage \"\"\"\n",
    "    blob = bucket.blob('sam-checkpoint/sam_vit_b_01ec64.pth')\n",
    "    blob.download_to_filename('sam_vit_b_01ec64.pth')\n",
    "    \n",
    "    \"\"\" Load the model \"\"\"\n",
    "    sam = sam_model_registry[\"vit_b\"](checkpoint=\"sam_vit_b_01ec64.pth\")\n",
    "    print(torch.cuda.is_available())\n",
    "    sam.to(\"cuda\")\n",
    "    \n",
    "    \"\"\" Automatic mask generation \"\"\"\n",
    "    mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "    \n",
    "    \"\"\" SAM Masking with prompts \"\"\"\n",
    "    predictor = SamPredictor(sam)\n",
    "    \n",
    "    \"\"\" Initialize Images \"\"\"\n",
    "    blobs = bucket.list_blobs(prefix=f\"{input_dir}/\")\n",
    "    image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    image_blobs = [blob for blob in blobs if blob.name.lower().endswith(image_extensions)]\n",
    "    \n",
    "    \"\"\" Load the Prompt JSON \"\"\"\n",
    "    blob = bucket.blob(f'{input_dir}/{prompt_json_file}')\n",
    "    if blob.exists():\n",
    "        prompt_json = json.loads(blob.download_as_text()) #returns prompts dictionary\n",
    "    else:\n",
    "        prompt_json = None\n",
    "    print(\"prompt_json\")\n",
    "    print(prompt_json)\n",
    "\n",
    "    \n",
    "    def reshape_image(image, size=512):\n",
    "        \"\"\"\n",
    "            Applies mask for an object in the image.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            image : np.ndarray\n",
    "                input image\n",
    "            size : int\n",
    "                size of resized image\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            ratio, resized_image\n",
    "            \n",
    "        \"\"\"\n",
    "        # Ratio for showing up in Markdown\n",
    "        if image.shape[0] < size and image.shape[1] < size: \n",
    "            ratio = 1\n",
    "        else: \n",
    "            ratio = size / max(image.shape[0], image.shape[1])\n",
    "        \n",
    "        width = int(image.shape[1] * ratio) #resized image width\n",
    "        height = int(image.shape[0] * ratio) #resized image height\n",
    "        resized_image = cv2.resize(image, (width, height)) # resized image\n",
    "        return ratio, resized_image\n",
    "\n",
    "    \"\"\" Prediction for all images \"\"\"\n",
    "    start_time_pred = time.time()\n",
    "    filenames, results = [], []\n",
    "    \n",
    "    for image_blob in image_blobs:\n",
    "        filename = image_blob.name.split('/')[-1]\n",
    "        filenames.append(filename)\n",
    "        start_time = time.time()\n",
    "        \"\"\" Downloading the image \"\"\"\n",
    "        image_blob.download_to_filename(filename)\n",
    "        print(f\"Image Downloading: {time.time() - start_time}s\")\n",
    "        \n",
    "        \"\"\" Reshape the image \"\"\"\n",
    "        ratio, image = reshape_image(cv2.cvtColor(cv2.imread(filename), cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        if prompt_json and filename in prompt_json: # Predicting with prompt inputs\n",
    "            \"\"\" Predicting with prompt inputs \"\"\"\n",
    "            prompt_info = prompt_json[filename]\n",
    "            prompt_input, label_input = [], []\n",
    "            \n",
    "            \"\"\" Adjusting prompt co-ordinates for the new resized image based on the ratio \"\"\"\n",
    "            for label, points in prompt_info.items():\n",
    "                for point in points:\n",
    "                    point = [int(c * ratio) for c in point]\n",
    "                    prompt_input.append(point)\n",
    "                    label_input.append(int(label))\n",
    "            \n",
    "            predictor.set_image(image)\n",
    "            start_time = time.time()\n",
    "            \n",
    "            \"\"\" Predicting with prompts \"\"\"\n",
    "            masks, scores, logits = predictor.predict(\n",
    "                                        point_coords=np.array(prompt_input),\n",
    "                                        point_labels=np.array(label_input),\n",
    "                                        multimask_output=False\n",
    "                                    )\n",
    "            print(f\"Prediction with Prompt: {time.time() - start_time}s\") # Time taken to predict\n",
    "            start_time = time.time()\n",
    "            \n",
    "            result = {\n",
    "                \"filename\": filename,\n",
    "                \"image\": image,\n",
    "                \"prediction_type\" : \"Predicting with Prompts\",\n",
    "                \"prompt_input\": prompt_input,\n",
    "                \"label_input\": label_input,\n",
    "                \"ratio\": ratio\n",
    "            }\n",
    "            result[\"masks\"], result[\"polygon_vertices\"] = {}, {}\n",
    "            for idx, mask in enumerate(masks[:max_mask]):\n",
    "                \"\"\" Perform Median Filtering on the mask\"\"\"\n",
    "                median_filter_size = int(min(mask.shape)//20)\n",
    "                if median_filter_size % 2 == 0:\n",
    "                    median_filter_size += 1\n",
    "                mask = median_filter(mask, median_filter_size)\n",
    "                result[\"masks\"][f'mask_{idx}'] = mask\n",
    "                \n",
    "                \"\"\" Generating Polygons representation of masks \"\"\"\n",
    "                polygons = Mask(mask).polygons()\n",
    "                result[\"polygon_vertices\"][f'mask_{idx}'] = list(map(lambda x: x.tolist(), polygons.points))\n",
    "            print(f\"Postprocessing {time.time() - start_time}s\")\n",
    "            \n",
    "        else: \n",
    "            start_time = time.time()\n",
    "            \n",
    "            \"\"\" Predicting without prompts / Automatic segmentation, segmenting all the objects in the image \"\"\"\n",
    "            masks = mask_generator.generate(image)\n",
    "            print(f\"Prediction without Prompt: {time.time() - start_time}s\")\n",
    "            result = {\n",
    "                \"filename\": filename,\n",
    "                \"image\": image,\n",
    "                \"prediction_type\" : \"Predicting without Prompts\",\n",
    "                \"ratio\": ratio\n",
    "            }\n",
    "            sorted_masks = sorted(masks, key=(lambda x: x['area']), reverse=True)\n",
    "            result[\"masks\"], result[\"polygon_vertices\"] = {}, {}\n",
    "            start_time = time.time()\n",
    "            \n",
    "            for idx, mask in enumerate(sorted(masks, key=(lambda x: x['area']), reverse=True)[:max_mask]):\n",
    "                \"\"\" Perform Median Filtering on the mask\"\"\"\n",
    "                mask = mask['segmentation']\n",
    "                median_filter_size = int(min(mask.shape)//20)\n",
    "                if median_filter_size % 2 == 0:\n",
    "                    median_filter_size += 1\n",
    "                mask = median_filter(mask, median_filter_size)\n",
    "                result[\"masks\"][f'mask_{idx}'] = mask\n",
    "                \n",
    "                \"\"\" Generating Polygons representation of masks \"\"\"\n",
    "                polygons = Mask(mask).polygons()\n",
    "                result[\"polygon_vertices\"][f'mask_{idx}'] = list(map(lambda x: x.tolist(), polygons.points))\n",
    "            print(f\"Postprocessing {time.time() - start_time}s\")\n",
    "            \n",
    "        results.append(result)\n",
    "        \n",
    "        \"\"\" Clearing Cache to avoid out of memory issue \"\"\"\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    print(f\"Time Taken for predictions, including preprocessing and postprocessing: {time.time() - start_time_pred}s\")\n",
    "\n",
    "    \"\"\" Export Images with masks to Output DIR in Cloud Storage \"\"\"\n",
    "    start_time = time.time()\n",
    "    alpha = 0.5\n",
    "    for filename, result in zip(filenames, results):\n",
    "        \"\"\" Saving the original image \"\"\"\n",
    "        original_image_blob = bucket.blob(f\"{output_dir}/{filename}/original.jpg\")\n",
    "        original_image_blob.upload_from_filename(filename)\n",
    "        for mask_name, mask in result[\"masks\"].items():\n",
    "            mask = np.array(mask)\n",
    "            plt.figure(figsize=(10,10))\n",
    "            plt.imshow(result['image'])\n",
    "            \n",
    "            \"\"\" Adding mask upon the image \"\"\"\n",
    "            show_mask(mask, plt)\n",
    "            \n",
    "            \"\"\" Showing markers on the object \"\"\"\n",
    "            if \"prompt_input\" in result:\n",
    "                input_point = np.array(result['prompt_input'])\n",
    "                input_label = np.array(result['label_input'])\n",
    "                show_points(input_point, input_label, plt)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            \"\"\" Saving the image \"\"\"\n",
    "            plt.savefig(f\"{mask_name}.jpg\")\n",
    "            plt.close()\n",
    "            \n",
    "            \"\"\" Upload the saved image to cloud storage \"\"\"\n",
    "            bucket.blob(f\"{output_dir}/{filename}/{mask_name}.jpg\").upload_from_filename(f\"{mask_name}.jpg\")\n",
    "    \n",
    "    print(f\"Time Taken for image exportations: {time.time() - start_time}s\")\n",
    "    \n",
    "    \"\"\" Export Results in JSON format to Output DIR \"\"\"\n",
    "    start_time = time.time()\n",
    "    for result in results:\n",
    "        output_result = {}\n",
    "        output_result[\"filename\"] = result[\"filename\"]\n",
    "        output_result[\"prediction_type\"] = result[\"prediction_type\"]\n",
    "        output_result[\"polygon_vertices\"] = result[\"polygon_vertices\"]\n",
    "        output_result[\"ratio\"] = result[\"ratio\"]\n",
    "        json_object = json.dumps(output_result, indent=4)\n",
    "        with open(\"result.json\", \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "        bucket.blob(f\"{output_dir}/{result['filename']}/result.json\").upload_from_filename(\"result.json\")\n",
    "    print(f\"Time Taken for json exportations: {time.time() - start_time}s\")\n",
    "        \n",
    "    \"\"\" Static Visualization / Adding all the images with masks to view in a markdown\"\"\"\n",
    "    with open(visualization.path, 'w') as f:\n",
    "        for result in results:\n",
    "            image = result[\"image\"]\n",
    "            f.write(f\"# {result['filename']} \\n\")\n",
    "            f.write(f\"## Prediction Type: {result['prediction_type']} \\n\")\n",
    "            f.write(\"<table>\")\n",
    "            f.write(\"<tr><td>\")\n",
    "            f.write(f'<img src=\"https://storage.cloud.google.com/{bucket_name}/{output_dir}/{result[\"filename\"]}/original.jpg\">')\n",
    "            f.write(\"</td>\")\n",
    "            f.write(\"<td></td><td></td><td></td></tr>\")\n",
    "            for idx, mask_name in enumerate(list(result[\"masks\"].keys())):\n",
    "                if idx % 4 == 0:\n",
    "                    f.write(\"<tr>\")\n",
    "                f.write(f'<td><img src=\"https://storage.cloud.google.com/{bucket_name}/{output_dir}/{result[\"filename\"]}/{mask_name}.jpg\"></td>')\n",
    "                if idx % 4 == 3:\n",
    "                    f.write(\"</tr>\")\n",
    "            if idx % 4 != 3:\n",
    "                f.write(\"</tr>\")\n",
    "            f.write(\"</table>\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a90a25-eebf-4a10-9ba7-0383d68f0c3a",
   "metadata": {},
   "source": [
    "### **Refer to [Pipeline Data Prep Notebook](./pipeline_exp_data_prep.ipynb) before proceeding further** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5d3c9-b5fc-44e7-9c7e-79a0ac902068",
   "metadata": {},
   "source": [
    "### **Pipeline Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fcf66db-b3af-4d01-a375-5468469446da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Set \"bucket_name\", \"input_dir\", \"output_dir\" and \"prompt_json_file\" to what is used in the pipeline used in the pipeline \"\"\" \n",
    "@pipeline(\n",
    "    pipeline_root= f\"gs://{bucket_name}/pipeline\",\n",
    "    name=\"sam-pipeline-test-batch-5\", # Name of the pipeline\n",
    ")\n",
    "def sam_pipeline(\n",
    "    bucket_name: str = \"{bucket_name}\",\n",
    "    input_dir: str = \"{input_dir}\", # Input directory with all the images\n",
    "    output_dir: str = \"{output_dir}\", # Output directory where all the results are stored\n",
    "    prompt_json_file: str = \"json_prompts/{prompt_json_file}\", # Prompts JSON file \n",
    "    max_mask: int = 10 #  Setting maximum number of masks per image\n",
    "):\n",
    "    get_batch_prediction_op = (batch_prediction(\n",
    "        bucket_name=bucket_name,\n",
    "        input_dir=input_dir, \n",
    "        output_dir=output_dir,\n",
    "        prompt_json_file=prompt_json_file,\n",
    "        max_mask=max_mask\n",
    "    )\n",
    "        .set_cpu_limit(\"8\")\n",
    "        .set_memory_limit(\"64G\")\n",
    "        .add_node_selector_constraint(\"cloud.google.com/gke-accelerator\", \"NVIDIA_TESLA_T4\")\n",
    "        .set_gpu_limit(1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "536847ff-ed5f-4bea-bfbb-943646b110dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=sam_pipeline,\n",
    "    package_path='sam_pipe_test.jsonl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb080531-87e7-4509-900c-ff221113dc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://sam_pipe_test.json [Content-Type=application/json]...\n",
      "/ [1 files][ 14.0 KiB/ 14.0 KiB]                                                \n",
      "Operation completed over 1 objects/14.0 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "\"\"\" Set the \"input_directory\" and \"bucket_name\" to the input directory and the bucket used in the pipeline\"\"\"\n",
    "!gsutil cp sam_pipe_test.jsonl gs://f{bucket_name}/f{input_directory}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b97146-8951-42dd-a087-c73ee06a949e",
   "metadata": {},
   "source": [
    "## Running the pipeline job from Notebook / It can also be done in Vertex AI console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f063d069-2ff6-4463-83fc-65316b00fd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/633534855904/locations/us-west1/pipelineJobs/sam-pipeline-test-batch-5-20230802044816\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/633534855904/locations/us-west1/pipelineJobs/sam-pipeline-test-batch-5-20230802044816')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-west1/pipelines/runs/sam-pipeline-test-batch-5-20230802044816?project=633534855904\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "job = aiplatform.PipelineJob(display_name = 'sam_pipeline_test_5',\n",
    "                             template_path = 'sam_pipe_test.json',\n",
    "                             enable_caching = False,\n",
    "                             # failure_policy = \"slow\",\n",
    "                             project=\"ml-ops-segment-anything\",\n",
    "                             location=\"us-west1\",\n",
    "                            )\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d422cdd-3047-4d33-9f7e-ac96a8db0390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' MAKE SURE TO CHECK KUBEFLOW VERSION IF FACING ISSUES RUNNING THE PIPELINE / v. 1.8.22 WORKS FINE'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" MAKE SURE TO CHECK KUBEFLOW VERSION IF FACING ISSUES RUNNING THE PIPELINE / v. 1.8.22 WORKS FINE\"\"\"\n",
    "#!pip install kfp==1.8.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dba581ee-65ae-4c74-a22f-7eaa10872363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list | grep \"kfp\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
